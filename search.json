[
  {
    "objectID": "releases.html",
    "href": "releases.html",
    "title": "Releases",
    "section": "",
    "text": "dupsifter releases can be found on the Releases page of GitHub. For details regarding each release, see the “Find it on GitHub” link below each release.\n\n0.1 Version 1.2.1\n\nLatest release\nReleased: 19 January 2024\nFind it on GitHub\n\n\n\n0.2 Version 1.2.0\n\nReleased: 26 September 2023\nFind it on GitHub\n\n\n\n0.3 Version 1.1.1\n\nReleased: 15 June 2023\nFind it on GitHub\n\n\n\n0.4 Version 1.1.0\n\nReleased: 8 June 2023\nFind it on GitHub\n\n\n\n0.5 Version 1.0.0\n\nReleased: 4 August 2022\nFind it on GitHub",
    "crumbs": [
      "Releases"
    ]
  },
  {
    "objectID": "methodology.html",
    "href": "methodology.html",
    "title": "Duplicate Marking Methodology",
    "section": "",
    "text": "Duplicate reads primarily come from two sources: polymerase chain reaction (PCR) and optical duplicates. Optical duplicates arise from the sequencer splitting a single cluster into two or more clusters (see the description in the paper for where these clusters come from). While dupsifter is able to handle optical duplicates, they affect WGS and WGBS datasets in the same way. Therefore, this section will focus on PCR duplicates and the differences in duplicate marking reads from these two technologies.\nPCR amplification is frequently used in WGS and WGBS to increase the amount of input DNA, which increases the chance of a DNA fragment being sequenced, but incurs a cost of some fragments being sequencing more than once. PCR duplicates are the result of multiple copies of the same fragment being sequenced. For WGS experiments, PCR proceeds as shown in Panel A of Figure 1. On the other hand, WGBS experiments include an additional step before PCR amplification is run. After the DNA is denatured, sodium bisulfite is added to the solution, converting unmethylated cytosines into uracils, which results in four distinct strands of DNA (see Panel B of Figure 1). These four strands are: one strand deriving from the original top (OT), one deriving from the original bottom (OB), and the two complements of these strands (CTOT and CTOB, respectively). This additional step means there are two distinct copies of DNA for a given DNA fragment in WGBS versus only one in WGS. Therefore, for WGBS experiments, we must distinguish between reads coming from the OT and OB strands at the same location and true PCR duplicates.\ndupsifter handles these differences by also factoring in the bisulfite strand (OT/CTOT or OB/CTOB) when determining if a read is a duplicate. In the case where the user is running in WGS mode, dupsifter treates all reads as coming from the same original strand.\n\n\n\n\n\n\nPart of Figure 1 from the dupsifter paper.\n\n\n\n\nFigure 1",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#differences-between-wgs-and-wgbs-duplicate-marking",
    "href": "methodology.html#differences-between-wgs-and-wgbs-duplicate-marking",
    "title": "Duplicate Marking Methodology",
    "section": "",
    "text": "Duplicate reads primarily come from two sources: polymerase chain reaction (PCR) and optical duplicates. Optical duplicates arise from the sequencer splitting a single cluster into two or more clusters (see the description in the paper for where these clusters come from). While dupsifter is able to handle optical duplicates, they affect WGS and WGBS datasets in the same way. Therefore, this section will focus on PCR duplicates and the differences in duplicate marking reads from these two technologies.\nPCR amplification is frequently used in WGS and WGBS to increase the amount of input DNA, which increases the chance of a DNA fragment being sequenced, but incurs a cost of some fragments being sequencing more than once. PCR duplicates are the result of multiple copies of the same fragment being sequenced. For WGS experiments, PCR proceeds as shown in Panel A of Figure 1. On the other hand, WGBS experiments include an additional step before PCR amplification is run. After the DNA is denatured, sodium bisulfite is added to the solution, converting unmethylated cytosines into uracils, which results in four distinct strands of DNA (see Panel B of Figure 1). These four strands are: one strand deriving from the original top (OT), one deriving from the original bottom (OB), and the two complements of these strands (CTOT and CTOB, respectively). This additional step means there are two distinct copies of DNA for a given DNA fragment in WGBS versus only one in WGS. Therefore, for WGBS experiments, we must distinguish between reads coming from the OT and OB strands at the same location and true PCR duplicates.\ndupsifter handles these differences by also factoring in the bisulfite strand (OT/CTOT or OB/CTOB) when determining if a read is a duplicate. In the case where the user is running in WGS mode, dupsifter treates all reads as coming from the same original strand.\n\n\n\n\n\n\nPart of Figure 1 from the dupsifter paper.\n\n\n\n\nFigure 1",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#duplicate-definition",
    "href": "methodology.html#duplicate-definition",
    "title": "Duplicate Marking Methodology",
    "section": "2 Duplicate Definition",
    "text": "2 Duplicate Definition\nAt its most basic, duplicates are those that match in all of the following categories (descriptions below):\n\nRead 1 Bin Number\nRead 1 Bin Position\nRead 2 Bin Number\nRead 2 Bin Position\nRead 1 Leftmost in Pair?\nOrientation\nSingle-end?\nCell barcode\n\n\n2.1 Descriptions\n\nRead 1/2 Bin Number: Bin number determination described in Section 3.\nRead 1/2 Bin Position: Position in bin described in Section 3.\nRead 1 Leftmost in Pair?: If paired-end, is read 1 the leftmost read? If single-end, then this is always false (0).\nOrientation: How reads are oriented, which can be one of four possibilities (given as read1-read2): forward-forward, reverse- reverse, forward-reverse, reverse-forward. For reference, forward-reverse is generally considered a “proper pair.”\nSingle-end?: Is the read a single-end read?\nCell barcode: Cell barcode for read. More details given in Section 5.\n\n\n\n2.2 Notes\nDuplicates are found for single-end and paired-end reads using the same set of categories, with a few minor notes. First, single-end reads and paired-end reads with one unmapped read in the pair are always considered to be “read 1” (read 2 is set to default values). The orientation can then be used to distinguish between reads on the forward and reverse strands. Second, the bin number and position are calculated individually for reads 1 and 2 in paired-end mode, which allows split and discordant reads to be properly marked as duplicates.\nWith respect to which read (or read pair) is chosen as the “non-duplicate,” dupsifter follows the likes of samblaster and deduplicate_bismark. Rather than choosing the read with the highest quality (which usually entails using the base qualities to determine “quality”), dupsifter sets the first read found in a set of duplicates as the non-duplicate. The authors of samblaster showed that choosing the first read, instead of the highest quality read, has little impact on the quality of reads going into downstream analyses. Further, it requires only one pass through the data, instead of two passes, which is required for methods that select the highest quality read.\nAstute observers may have noticed there is no reference to bisulfite strand in the duplicate definition. This is a byproduct of the technical implementation of dupsifter and is due to the bisulfite strand being handled separately from the explicit definition of a duplicate.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#sec-binning",
    "href": "methodology.html#sec-binning",
    "title": "Duplicate Marking Methodology",
    "section": "3 Reference Padding and Binning",
    "text": "3 Reference Padding and Binning\nPadding the length of chromosomes and other contigs is needed due to the possibility of soft clipped reads. dupsifter uses the unclipped read length in order to determine duplicates, which requires subtracting or adding the number of clipped bases from the start or end position, respectively. In the extreme case where a heavily clipped read is located at the start or end of a chromosome/contig, the adjusted position can occur outside of the defined chromosome bounds. Therefore, the maximum read length (set by the -l/--max-read-length) is added to each end of the chromosome/contig to account for this possibility. In the instance where a read is longer than the maximum read length, the code will produce an error requesting the user to rerun with a longer maximum read length set.\nGenerally, duplicate marking tools bin the genome based on the number of contigs (1 contig = 1 bin). For genomes with a small number of contigs, this isn’t a problem. However, for genomes with a large number of contigs (e.g., plant genomes), this becomes impractical. dupsifter, on the other hand, takes a different approach (based on the solution proposed in this issue raised on samblaster’s GitHub page). In this method, the entire genome is combined into one “supercontig”, which is then divided into bins of roughly equal size. By way of example, the human genome from GENCODE contains over 600 contigs (both primary chromosomes and additional contigs). Rather than having 600+ bins, there are approximately 25 bins using this method. With respect to the read position, by combining the contigs in the order listed in the SAM header, an offset from the start of the first contig can be calculated for each additional contig. This offset includes padding at the start and end of each previous contig (described above), plus the padding at the start of the current contig. By adding the position on the contig (using the read’s CIGAR string) to the offset, the specific bin the read falls into can be determined, as well as the position within the bin itself.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#bisulfite-strand-determination",
    "href": "methodology.html#bisulfite-strand-determination",
    "title": "Duplicate Marking Methodology",
    "section": "4 Bisulfite Strand Determination",
    "text": "4 Bisulfite Strand Determination\nThe bisulfite strand for a read (both single-end and paired-end reads) is determined with the following priority:\n\nbwa-meth flag (YD)\nbsmap flag (ZS)\nbismark flag (XG)\nInference from number of C→T (nCT) and G→A (nGA) substitutions (OT/CTOT if nCT &gt;= nGA, else OB/CTOB)\n\nFor paired-end reads, the bisulfite strand is individually determined for both read 1 (bss1) and read 2 (bss2), then any differences between the two are resolved.\n\nIf bss1 == bss2, then bss1 is used.\nIf only bss1 (or bss2) is found, then bss1 (or bss2) is used.\nIf neither bss1 or bss2 are found, then assume OT/CTOT.\nIf both bss1 and bss2 are found, but bss1 != bss2, then the sum of the base qualities is used to determine which to use. If sum(read 1 base qualities) &gt; sum(read 2 base qualities), then bss1 is used, else bss2 is used.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "methodology.html#sec-barcodes",
    "href": "methodology.html#sec-barcodes",
    "title": "Duplicate Marking Methodology",
    "section": "5 Cell Barcodes",
    "text": "5 Cell Barcodes\nCell barcodes are commonly used in single-cell sequencing in order to multiplex many cells into a pool, primarily to increase throughput and to overcome sequencer input requirements. It also allows for streamlined processing, as many cells can be processed at once. These barcodes must be included when defining reads that are duplicates as two fragments may be from the same location in the genome, but come from two different cells. By default, dupsifter does not look for barcodes; however, an option is available (-B/--has-barcode) when duplicate marking data with barcodes. dupsifter handles barcodes in the following way:\n\nLooks for the CB SAM tag.\nIf not found, looks for the CR SAM tag.\nIf neither are found, parse the read name. The barcode must be the last element in the name, where the elements are separated by :.\nIf a barcode can’t be found in any of these locations, a warning is printed and a default value is used (thereby negating any benefits of using barcodes).\n\nIn all three cases, up to 16 bases are packed into a single integer for defing the barcode. If your barcode is longer than 16 bases, it will be truncated to a length of 16. Additionally, separators (only + and - are allowed) are treated as N’s and count towards the maximum length of 16.",
    "crumbs": [
      "Methodology"
    ]
  },
  {
    "objectID": "examples.html",
    "href": "examples.html",
    "title": "Examples",
    "section": "",
    "text": "Below you will find various examples of how to use dupsifter. Example datasets can be found in the example directory of the dupsifter source code.",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "examples.html#basic-usage",
    "href": "examples.html#basic-usage",
    "title": "Examples",
    "section": "1 Basic Usage",
    "text": "1 Basic Usage\nInput to dupsifter comes from either the terminal’s standard input (i.e., streamed input) or with an input BAM file. The default output is to the terminal’s standard output (i.e., streamed output), but it can also be written straight to an output file (the -o/--output option).\nExamples of reading streamed input, such as from tools like biscuit and bwa-meth which stream their output, are:\n# Streamed input and streamed output with BISCUIT\nbiscuit align -@ 8 -b 1 hg38.fa read1.fastq read2.fastq | \\\ndupsifter hg38.fa | \\\nsamtools sort -@ 2 -o biscuit.sorted.markdup.bam -\n\n# Streamed input and output BAM with bwa-meth\nbwameth.py \\\n    --threads 8 \\\n    --reference hg38.fa \\\n    read1.fastq \\\n    read2.fastq | \\\ndupsifter -o bwameth.unsorted.markdup.bam hg38.fa\nOn the other hand, tools such as bismark and bsbolt default to writing a BAM file as output from their alignment. An example of using an input BAM and writing to an output BAM or streaming the output to another tool:\n# Input BAM and output BAM with Bismark\nbismark \\\n    --parallel 2 \\\n    --genome hg38 \\\n    -1 read1.fastq \\\n    -2 read2.fastq\n\ndupsifter -o bismark.unsorted.markdup.bam hg38.fa read1_bismark_bt2_pe.bam\n\n# Input BAM and streamed output with BSBolt\nbsbolt Align \\\n    -t 8 \\\n    -DB hg38 \\\n    -O bsbolt.unsorted \\\n    -F1 read1.fastq \\\n    -F2 read2.fastq\n\ndupsifter hg38.fa bsbolt.unsorted.bam | \\\nsamtools sort -@ 2 -o bsbolt.sorted.markdup.bam -\ndupsifter expects it’s input to be read-name grouped (i.e., reads with the same name next to one another in the BAM), which is how reads are output from biscuit, bismark, bsbolt, and bwa-meth. gemBS, on the other hand, performs position sorting during its alignment. Therefore, if you want to use dupsifter with BAMs from gemBS, you will have to group the reads by name with either samtools sort or samtools collate. An example with samtools sort is:\n# Alignment with gemBS\n# gembs.hg38.conf and gembs.sample.conf are configuration files that are specified ahead of time\n# The output BAM from gemBS in this example is gembs.position_sorted.bam\ngemBS prepare -c gembs.hg38.conf -t gembs.sample.conf\ngemBS map\n\nsamtools sort -n -o gembs.name_sorted.bam gembs_position_sorted.bam\n\ndupsifter -o gembs.name_sorted.markdup.bam hg38.fa gembs.name_sorted.bam",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "examples.html#additional-usage",
    "href": "examples.html#additional-usage",
    "title": "Examples",
    "section": "2 Additional Usage",
    "text": "2 Additional Usage\n\n2.1 Single-end vs Paired-end Reads\ndupsifter defaults to running for paired-end reads. In cases where single-end reads were aligned, include the -s/--single-end option:\ndupsifter --single-end -o ouput.bam hg38.fa input.bam\n\n\n2.2 Adding Mate Tags\nFor aligners that don’t generate mate tags (MC and MQ), dupsifter includes an option (-m/--add-mate-tags) for adding mate tags during the duplicate marking stage:\ndupsifter --add-mate-tags -o ouput.bam hg38.fa input.bam\n\n\n\n\n\n\nNote\n\n\n\nIf a read already has one or both of the mate tags and --add-mate-tags is included, the pre-existing tags will not be overwritten.\n\n\n\n\n2.3 Duplicate Marking WGS Data\nWhile dupsifter was written for WGBS data, it can also be used to mark WGS data with the -W/--wgs-only option:\nbwa mem hg38.fa read1.fq.gz read2.fq.gz | \\\ndupsifter --wgs-only -o output.bam hg38.fa\n\n\n2.4 Adjusting the Maximum Read Length\nFor long-read data, the default maximum read length may not be sufficient. In this case, you can increase the maximum length with the -l/--max-read-length option:\ndupsifter --max-read-length 20000 -o output.bam hg38.fa input.bam\n\n\n\n\n\n\nNote\n\n\n\nFor current short-read technologies, the default value is more than sufficient.\n\n\n\n\n2.5 Adjusting the Minimum Base Quality\nFor cases where the bisulfite strand information is not included, dupsifter infers the strand based on the number of C→T and G→A substitutions. By default, all bases in a read are used for counting the number of each substitution. However, in the case where a user wants to only use bases that meet a certain base quality threshold, you can adjust the minimum base quality with -b/--min-base-qual:\ndupsifter --min-base-qual 20 -o output.bam hg38.fa input.bam\n\n\n\n\n\n\nNote\n\n\n\nThis option is only used when the bisulfite strand has to be inferred and is ignored otherwise.\n\n\n\n\n2.6 Duplicate Marking for Reads with Cell Barcodes\nFor experiments that include cell barcodes, dupsifter is able to include the cell barcode as part of its signature with the -B/--has-barcode option:\ndupsifter --has-barcode -o output.bam hg38.fa input.bam\nFor more details on how the cell barcode can be included in the read entry, see dupsifter --help or the Methodology page.\n\n\n2.7 Removing Duplicates\nTypically, downstream analysis tools will ignore reads flagged as duplicates that are left in the BAM file, but in cases where duplicates reads must be removed, you can remove duplicates with the -r/--remove-dups option:\ndupsifter --remove-dups -o output.bam hg38.fa input.bam",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "examples.html#test-cases",
    "href": "examples.html#test-cases",
    "title": "Examples",
    "section": "3 Test Cases",
    "text": "3 Test Cases\nBAM files aligned with biscuit, bismark, bsbolt, bwa-meth, and gemBS, as well as the FASTQ files used to generate them, have been provided for practicing using dupsifter and can be found in the example directory of the dupsifter source code. Below are the results found in the output stats file for each run. All examples are created from hg38 without contigs. For testing purposes, any hg38 reference that conforms to the UCSC naming scheme (i.e., chr1 not 1) should work to recreate the results shown.\n\n\n\n\n\n\nTest Case Data Creation\n\n\n\nThe following tool versions were used for the test cases:\n\n\n\n\n\n\n\n\ntool\nversion\n\n\n\n\nbiscuit\n1.2.1\n\n\nbismark\n0.24.0\n\n\nbsbolt\n1.6.0\n\n\nbwa-meth\n0.2.6\n\n\ngemBS\n4.0.4\n\n\nsamtools\n1.17\n\n\ndupsifter\n1.2.0\n\n\n\n\n\n\n\n\nFASTQ files were were generated with Sherman:\nSherman \\\n    -l 150 \\\n    -n 900 \\\n    --CG_conversion 70 \\\n    --CH_conversion 1 \\\n    --genome_folder hg38_noContig \\\n    --paired_end \\\n    --bwa_ending\n100 duplicates were then randomly selected using Python (random seed set to 2023) and appended to the FASTQ files created by Sherman. This produced a FASTQ with a duplicate rate of 10% (100 read pairs out of 1000).\n\n\n\n3.1 BISCUIT\n$ dupsifter \\\n$     -o biscuit.unsorted.markdup.bam \\\n$     -O biscuit.dupsifter.stats \\\n$     hg38_noContig.fa \\\n$     biscuit.unsorted.bam\n$\n$ cat biscuit.dupsifter.stats\n[dupsifter] processing mode: paired-end\n[dupsifter] number of individual reads processed: 2000\n[dupsifter] number of reads with both reads mapped: 1000\n[dupsifter] number of reads with only one read mapped to the forward strand: 0\n[dupsifter] number of reads with only one read mapped to the reverse strand: 0\n[dupsifter] number of reads with both reads marked as duplicates: 97\n[dupsifter] number of reads on the forward strand marked as duplicates: 0\n[dupsifter] number of reads on the reverse strand marked as duplicates: 0\n[dupsifter] number of individual primary-alignment reads: 2000\n[dupsifter] number of individual secondary- and supplementary-alignment reads: 0\n[dupsifter] number of reads with no reads mapped: 0\n[dupsifter] number of reads with no primary reads: 0\n\n\n\n\n\n\nWarning\n\n\n\nTo briefly highlight one of the pitfalls of marking duplicates, the reason there are not the expected 100 duplicates from the biscuit data (similarly in bismark, bsbolt, and bwa-meth) is due to the aligner choosing different mapping locations for reads with multiple, equally likely potential locations. An example is shown here:\n103_chr3:92733152-92733265  99  chr3  92815142  0  150M  =  92815106  114  (remainder not shown)\n103_chr3:92733152-92733265  147  chr3  92815106  0  150M  =  92815142  114  (remainder not shown)\ndup_103_chr3:92733152-92733265  99  chr3  93567084  0  150M  =  93567048  114  (remainder not shown)\ndup_103_chr3:92733152-92733265  147  chr3  93567048  0  150M  =  93567084  114  (remainder not shown)\n\n\n\n\n3.2 Bismark\n$ dupsifter \\\n$     -o bismark.unsorted.markdup.bam \\\n$     -O bismark.dupsifter.stats \\\n$     hg38_noContig.fa \\\n$     bismark.unsorted.bam\n$\n$ cat bismark.dupsifter.stats\n[dupsifter] processing mode: paired-end\n[dupsifter] number of individual reads processed: 1924\n[dupsifter] number of reads with both reads mapped: 962\n[dupsifter] number of reads with only one read mapped to the forward strand: 0\n[dupsifter] number of reads with only one read mapped to the reverse strand: 0\n[dupsifter] number of reads with both reads marked as duplicates: 96\n[dupsifter] number of reads on the forward strand marked as duplicates: 0\n[dupsifter] number of reads on the reverse strand marked as duplicates: 0\n[dupsifter] number of individual primary-alignment reads: 1924\n[dupsifter] number of individual secondary- and supplementary-alignment reads: 0\n[dupsifter] number of reads with no reads mapped: 0\n[dupsifter] number of reads with no primary reads: 0\n\n\n\n\n\n\nWarning\n\n\n\nDuring alignment, bismark splits the FASTQ into chunks when aligning with more than one thread. The aligned reads are then merged into one output BAM; however, the read order is not necessarily the same as in the FASTQ. This provides an opportunity to highlight dupsifter choosing the first read found with a given signature as the “non-duplicate.” In read1.fastq, all reads that were selected as duplicates of the simulated reads had dup_ prepended to the name and were placed at the end of the FASTQ. However, during alignment, some of the reads ended up before the original read in the BAM. Below is an example of the original read being marked as a duplicate.\ndup_80_chr16:52422066-52422154/1  99  chr16  52422066  42  150M  =  52422005  211  (remainder not shown)\ndup_80_chr16:52422066-52422154/1  147  chr16  52422005  42  150M  =  52422066  -211  (remainder not shown)\n80_chr16:52422066-52422154/1  1123  chr16  52422066  42  150M  =  52422005  211  (remainder not shown)\n80_chr16:52422066-52422154/1  1171  chr16  52422005  42  150M  =  52422066  -211  (remainder not shown)\nWhile there is a known order to the reads in this simulated example, the original template strand that PCR duplicates were created from in a real experiment cannot be distinguished. Therefore, choosing the first appearance of a given signature is a reasonable choice for the “non-duplicate.”\n\n\n\n\n3.3 BSBolt\n$ dupsifter \\\n$     -o bsbolt.unsorted.markdup.bam \\\n$     -O bsbolt.dupsifter.stats \\\n$     hg38_noContig.fa \\\n$     bsbolt.unsorted.bam\n$\n$ cat bsbolt.dupsifter.stats\n[dupsifter] processing mode: paired-end\n[dupsifter] number of individual reads processed: 2000\n[dupsifter] number of reads with both reads mapped: 977\n[dupsifter] number of reads with only one read mapped to the forward strand: 0\n[dupsifter] number of reads with only one read mapped to the reverse strand: 0\n[dupsifter] number of reads with both reads marked as duplicates: 97\n[dupsifter] number of reads on the forward strand marked as duplicates: 0\n[dupsifter] number of reads on the reverse strand marked as duplicates: 0\n[dupsifter] number of individual primary-alignment reads: 2000\n[dupsifter] number of individual secondary- and supplementary-alignment reads: 0\n[dupsifter] number of reads with no reads mapped: 23\n[dupsifter] number of reads with no primary reads: 0\n\n\n3.4 bwa-meth\n$ dupsifter \\\n$     -o bwameth.unsorted.markdup.bam \\\n$     -O bwameth.dupsifter.stats \\\n$     hg38_noContig.fa \\\n$     bwameth.unsorted.bam\n$\n$ cat bwameth.dupsifter.stats\n[dupsifter] processing mode: paired-end\n[dupsifter] number of individual reads processed: 2000\n[dupsifter] number of reads with both reads mapped: 1000\n[dupsifter] number of reads with only one read mapped to the forward strand: 0\n[dupsifter] number of reads with only one read mapped to the reverse strand: 0\n[dupsifter] number of reads with both reads marked as duplicates: 97\n[dupsifter] number of reads on the forward strand marked as duplicates: 0\n[dupsifter] number of reads on the reverse strand marked as duplicates: 0\n[dupsifter] number of individual primary-alignment reads: 2000\n[dupsifter] number of individual secondary- and supplementary-alignment reads: 0\n[dupsifter] number of reads with no reads mapped: 0\n[dupsifter] number of reads with no primary reads: 0\n\n\n3.5 gemBS\n$ samtools sort -n -o gembs.name_sorted.bam gembs.position_sorted.bam\n$\n$ dupsifter \\\n$     -o gembs.name_sorted.markdup.bam \\\n$     -O gembs.dupsifter.stats \\\n$     hg38_noContig.fa \\\n$     gembs.name_sorted.bam\n$\n$ cat gembs.dupsifter.stats\n[dupsifter] processing mode: paired-end\n[dupsifter] number of individual reads processed: 2000\n[dupsifter] number of reads with both reads mapped: 1000\n[dupsifter] number of reads with only one read mapped to the forward strand: 0\n[dupsifter] number of reads with only one read mapped to the reverse strand: 0\n[dupsifter] number of reads with both reads marked as duplicates: 100\n[dupsifter] number of reads on the forward strand marked as duplicates: 0\n[dupsifter] number of reads on the reverse strand marked as duplicates: 0\n[dupsifter] number of individual primary-alignment reads: 2000\n[dupsifter] number of individual secondary- and supplementary-alignment reads: 0\n[dupsifter] number of reads with no reads mapped: 0\n[dupsifter] number of reads with no primary reads: 0",
    "crumbs": [
      "Examples"
    ]
  },
  {
    "objectID": "usage.html",
    "href": "usage.html",
    "title": "Usage",
    "section": "",
    "text": "dupsifter is able to accept input from stdin or from an input SAM/BAM file. Output can be directed either to stdout or to an output SAM/BAM. Input and output options can be mixed as needed (i.e., input BAM to streamed output).\n\n\n\n\n\n\nNote\n\n\n\nThe input to dupsifter is expected to be read-name grouped (i.e., reads with same name next to one another in the BAM). If you supply a position sorted BAM, it will produce an error message along the lines of:\n[dupsifter] ERROR: Can't find read 1 and/or read 2 in 1 reads with read ID: &lt;name of read&gt;.\nAre these reads coordinate sorted?",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#input-output",
    "href": "usage.html#input-output",
    "title": "Usage",
    "section": "",
    "text": "dupsifter is able to accept input from stdin or from an input SAM/BAM file. Output can be directed either to stdout or to an output SAM/BAM. Input and output options can be mixed as needed (i.e., input BAM to streamed output).\n\n\n\n\n\n\nNote\n\n\n\nThe input to dupsifter is expected to be read-name grouped (i.e., reads with same name next to one another in the BAM). If you supply a position sorted BAM, it will produce an error message along the lines of:\n[dupsifter] ERROR: Can't find read 1 and/or read 2 in 1 reads with read ID: &lt;name of read&gt;.\nAre these reads coordinate sorted?",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#run-statistics",
    "href": "usage.html#run-statistics",
    "title": "Usage",
    "section": "2 Run Statistics",
    "text": "2 Run Statistics\nEach run of dupsifter calculates statistics related to the number of duplicates and the types of reads processed. By default, the output file is named dupsifter.stat if the output is streamed or basename.dupsifter.stat if the output file is defined (-o basename.bam). The statistics file name can also be defined with the -O option (i.e., dupsifter -O output.dupsifter.stat ref.fa input.bam). If using the -O option, the file should end with .dupsifter.stat. If both -o and -O are provided, then the -O file name will be used.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#help",
    "href": "usage.html#help",
    "title": "Usage",
    "section": "3 Help",
    "text": "3 Help\nProgram: dupsifter\nVersion: 1.2.1\nContact: Jacob Morrison &lt;jacob.morrison@vai.org&gt;\n\ndupsifter [options] &lt;ref.fa&gt; [in.bam]\n\nOutput options:\n    -o, --output STR             name of output file [stdout]\n    -O, --stats-output STR       name of file to write statistics to (see Note 3 for details)\nInput options:\n    -s, --single-end             run for single-end data\n    -m, --add-mate-tags          add MC and MQ mate tags to mate reads\n    -W, --wgs-only               process WGS reads instead of WGBS\n    -l, --max-read-length INT    maximum read length for paired end duplicate-marking [10000]\n    -b, --min-base-qual INT      minimum base quality [0]\n    -B, --has-barcode            reads in file have barcodes (see Note 4 for details)\n    -r, --remove-dups            toggle to remove marked duplicate\n    -v, --verbose                print extra messages\n    -h, --help                   this help\n        --version                print version info and exit\n\nNote 1, [in.bam] must be name sorted. If not provided, assume the input is stdin.\nNote 2, assumes either ALL reads are paired-end (default) or single-end.\n    If a singleton read is found in paired-end mode, the code will break nicely.\nNote 3, defaults to dupsifter.stat if streaming or (-o basename).dupsifter.stat\n    if the -o option is provided. If -o and -O are provided, then -O will be used.\nNote 4, dupsifter first looks for a barcode in the CB SAM tag, then in the CR SAM tag, then\n    tries to parse the read name. If the barcode is in the read name, it must be the last element\n    and be separated by a ':' (i.e., @12345:678:9101112:1234_1:N:0:ACGTACGT). Any separators\n    found in the barcode (e.g., '+' or '-') are treated as 'N's and the additional parts of the\n    barcode are included up to a maximum length of 16 bases/characters. Barcodes are taken from\n    read 1 in paired-end sequencing only.",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "usage.html#option-descriptions",
    "href": "usage.html#option-descriptions",
    "title": "Usage",
    "section": "4 Option Descriptions",
    "text": "4 Option Descriptions\n\n\n\n\nShort Option\nLong Option\nArgument Type\nDescription\n\n\n\n\n-o\n--output\nstring\nName of output file (either .sam or .bam)\n\n\n-O\n--stats-output\nstring\nName of file to write statistics to (end with .dupsifter.stat)\n\n\n-s\n--single-end\nnone\nRun for single-end data (only do this if you know the data is SE)\n\n\n-m\n--add-mate-tags\nnone\nAdd MC (mate CIGAR) and MQ (mate MAPQ) tags to mated reads\n\n\n-W\n--wgs-only\nnone\nProcess WGS data instead of WGBS (see Methodology for differences in processing)\n\n\n-l\n--max-read-length\ninteger\nMaximum read length (handles padding for reference genome windows)\n\n\n-b\n--min-base-qual\ninteger\nMinimum base quality (used in determining bisulfite strand if tags not provided)\n\n\n-B\n--has-barcode\nnone\nUse when reads have cell barcodes and you want to mark duplicates accordingly\n\n\n-r\n--remove-dups\nnone\nRemove reads that are flagged as duplicates\n\n\n-v\n--verbose\nnone\nPrint extra messages when running\n\n\n-h\n--help\nnone\nPrint usage help message and exit\n\n\n\n--version\nnone\nPrint dupsifter version and exit",
    "crumbs": [
      "Usage"
    ]
  },
  {
    "objectID": "install.html",
    "href": "install.html",
    "title": "Installation",
    "section": "",
    "text": "Note\n\n\n\nIf you plan to use the Docker container or install via conda/mamba you can skip this section as all dependencies are wrapped up in these methods.\n\n\nIf you plan to compile your own copy of dupsifter or run the pre-compiled binaries, there are several external dependencies that are needed:\nzlib\nlibbz2\nliblzma\nlibcurl\nSome helpful tools for retrieving the pre-compiled binaries or the source code from GitHub are:\ngit\ncurl\nunzip\nIf you are compiling dupsifter yourself, you will also need:\ngcc\nmake",
    "crumbs": [
      "Download/Install"
    ]
  },
  {
    "objectID": "install.html#external-dependencies",
    "href": "install.html#external-dependencies",
    "title": "Installation",
    "section": "",
    "text": "Note\n\n\n\nIf you plan to use the Docker container or install via conda/mamba you can skip this section as all dependencies are wrapped up in these methods.\n\n\nIf you plan to compile your own copy of dupsifter or run the pre-compiled binaries, there are several external dependencies that are needed:\nzlib\nlibbz2\nliblzma\nlibcurl\nSome helpful tools for retrieving the pre-compiled binaries or the source code from GitHub are:\ngit\ncurl\nunzip\nIf you are compiling dupsifter yourself, you will also need:\ngcc\nmake",
    "crumbs": [
      "Download/Install"
    ]
  },
  {
    "objectID": "install.html#download-and-install",
    "href": "install.html#download-and-install",
    "title": "Installation",
    "section": "2 Download and Install",
    "text": "2 Download and Install\nAll releases are available on GitHub.\n\n2.1 Precompiled Binaries\nPrecompiled binaries are available for macOS and Linux:\n# macOS\ncurl -L $(curl -s https://api.github.com/repos/huishenlab/dupsifter/releases/latest |\n    grep browser_download_url | grep darwin_amd64 | cut -d '\"' -f 4) --output dupsifter\nchmod +x dupsifter\n\n# Linux\ncurl -L $(curl -s https://api.github.com/repos/huishenlab/dupsifter/releases/latest |\n    grep browser_download_url | grep linux_amd64 | cut -d '\"' -f 4) --output dupsifter\nchmod +x dupsifter\n\n\n2.2 Build from Source\ndupsifter can also be downloaded and built from source.\nVia git:\ngit clone git@github.com:huishenlab/dupsifter.git\ncd dupsifter\nmake\nOr, via curl:\ncurl -OL $(curl -s https://api.github.com/repos/huishenlab/dupsifter/releases/latest |\n    grep browser_download_url | grep release-source.zip | cut -d '\"' -f 4)\nunzip release-source.zip\ncd dupsifter-release\nmake\n\n\n2.3 Containers\nA Dockerfile is available to build a dupsifter container for the latest release version:\ngit clone git@github.com:huishenlab/dupsifter.git\ncd dupsifter/container\ndocker build --no-cache --tag dupsifter_latest --file Dockerfile_latest .\ndocker run -it dupsifter_latest /bin/bash\nIf preferred, you can instead create a Dockerfile for a specific release of dupsifter. For version X.Y.Z, you can do this via:\ngit clone git@github.com:huishenlab/dupsifter.git\ncd dupsifter/container\npython create_container.py -v X.Y.Z\ndocker build --no-cache --tag dupsifter_vX.Y.Z --file Dockerfile_vX.Y.Z .\ndocker run -it dupsifter_vX.Y.Z /bin/bash\nIf you don’t want to build the container yourself, a pre-built container is available on DockerHub and can be pulled down with either Docker or Singularity:\n# Docker\ndocker pull varishenlab/dupsifter:dupsifter_v1.2.1\ndocker run -it varishenlab:dupsifter /bin/bash\n\n# Singularity\nsingularity pull dupsifter.sif docker://varishenlab/dupsifter:dupsifter_v1.2.1\nsingularity shell -B /path/to/dupsifter/code dupsifter.sif\nSingularity&gt; cd /path/to/dupsifter/code\nSingularity&gt; make\n\n\n2.4 Bioconda\ndupsifter is also available via conda/mamba (starting with version 1.2.0):\nconda install -c bioconda dupsifter",
    "crumbs": [
      "Download/Install"
    ]
  },
  {
    "objectID": "troubleshooting.html",
    "href": "troubleshooting.html",
    "title": "Troubleshooting",
    "section": "",
    "text": "Arises when either the input or output file/stream can’t be opened. This may occur for a variety of reasons, including missing input files, incorrectly named files, hard disk space that is too small to open the output file, or a lack of permissions to write to a directory.\n\n\n\ndupsifter needs a reference FASTA in order to infer the bisulfite strand if a strand tag is not found in the read. Add a reference to your command line invocation and try again. See the Usage page for help with running dupsifter.\n\n\n\nThis serves as a basic check that the correct file type is being used as the reference input. Check you have your inputs in the correct order and that any reference FASTA files have the proper extensions.\n\n\n\nArises when dupsifter encounters a read that is longer than the specified max read length. This ensures that no reads would run beyond the specified padding around the chromosome lengths. Rerunning dupsifter with a longer max read length (the --max-read-length option) should resolve this issue.\n\n\n\nArises when input that isn’t read-name grouped is provided to dupsifter. This can be resolved by name sorting or collating your SAM/BAM with samtools sort -n or samtools collate and then providing the sorted input to dupsifter.\n\n\n\nThe input file has no reads. This may be either from a completely file or a SAM/BAM file that has a header, but no reads. Double check the contents of your input.\n\n\n\nCan either occur for single/mate-unmapped reads or paired-end reads. Arises from an error reading a SAM entry. Check your input file to ensure it is not corrupted.\n\n\n\nArises when dupsifter encounters a CIGAR operation that it doesn’t recognize. This error is most likely to occur in versions 1.2.0 and earlier when you use input from tools that make use of extended CIGAR operations (= and X). If this is your issue, upgrading to at least version 1.2.1 should resolve your problem.\n\n\n\nArises when a read orientation (see the Methodology page for details on read orientation) is encountered that dupsifter does not recognize. Please open an issue if you encounter this error.\n\n\n\ndupsifter failed to collect all command line arguments and form the PG SAM tag string. Try running dupsifter again.\n\n\n\ndupsifter could not write PG SAM tag to the SAM header for output. Likely due to a corruption in the SAM header of the input file itself or a lack of sufficient memory to add the PG tag contents to the header.\n\n\n\ndupsifter could not write the SAM header for output. May occur due to an inability to write to the output file or a corrupt SAM header.",
    "crumbs": [
      "Troubleshooting"
    ]
  },
  {
    "objectID": "troubleshooting.html#runtime-errors",
    "href": "troubleshooting.html#runtime-errors",
    "title": "Troubleshooting",
    "section": "",
    "text": "Arises when either the input or output file/stream can’t be opened. This may occur for a variety of reasons, including missing input files, incorrectly named files, hard disk space that is too small to open the output file, or a lack of permissions to write to a directory.\n\n\n\ndupsifter needs a reference FASTA in order to infer the bisulfite strand if a strand tag is not found in the read. Add a reference to your command line invocation and try again. See the Usage page for help with running dupsifter.\n\n\n\nThis serves as a basic check that the correct file type is being used as the reference input. Check you have your inputs in the correct order and that any reference FASTA files have the proper extensions.\n\n\n\nArises when dupsifter encounters a read that is longer than the specified max read length. This ensures that no reads would run beyond the specified padding around the chromosome lengths. Rerunning dupsifter with a longer max read length (the --max-read-length option) should resolve this issue.\n\n\n\nArises when input that isn’t read-name grouped is provided to dupsifter. This can be resolved by name sorting or collating your SAM/BAM with samtools sort -n or samtools collate and then providing the sorted input to dupsifter.\n\n\n\nThe input file has no reads. This may be either from a completely file or a SAM/BAM file that has a header, but no reads. Double check the contents of your input.\n\n\n\nCan either occur for single/mate-unmapped reads or paired-end reads. Arises from an error reading a SAM entry. Check your input file to ensure it is not corrupted.\n\n\n\nArises when dupsifter encounters a CIGAR operation that it doesn’t recognize. This error is most likely to occur in versions 1.2.0 and earlier when you use input from tools that make use of extended CIGAR operations (= and X). If this is your issue, upgrading to at least version 1.2.1 should resolve your problem.\n\n\n\nArises when a read orientation (see the Methodology page for details on read orientation) is encountered that dupsifter does not recognize. Please open an issue if you encounter this error.\n\n\n\ndupsifter failed to collect all command line arguments and form the PG SAM tag string. Try running dupsifter again.\n\n\n\ndupsifter could not write PG SAM tag to the SAM header for output. Likely due to a corruption in the SAM header of the input file itself or a lack of sufficient memory to add the PG tag contents to the header.\n\n\n\ndupsifter could not write the SAM header for output. May occur due to an inability to write to the output file or a corrupt SAM header.",
    "crumbs": [
      "Troubleshooting"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Dupsifter Documentation",
    "section": "",
    "text": "dupsifter is a command line tool for marking duplicates in both WGS and WGBS datasets. It is based on the samblaster methodology for finding and marking duplicates.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#publication",
    "href": "index.html#publication",
    "title": "Dupsifter Documentation",
    "section": "1 Publication",
    "text": "1 Publication\nIf you use dupsifter, kindly cite:\nJacob Morrison, Wanding Zhou, Benjamin K Johnson, Hui Shen,\nDupsifter: a lightweight duplicate marking tool for whole genome bisulfite sequencing,\nBioinformatics, Volume 39, Issue 12, December 2023, btad729,\nhttps://doi.org/10.1093/bioinformatics/btad729",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#issues",
    "href": "index.html#issues",
    "title": "Dupsifter Documentation",
    "section": "2 Issues",
    "text": "2 Issues\nIssues and bugs can be submitted to: https://github.com/huishenlab/dupsifter/issues.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "index.html#acknowledgments",
    "href": "index.html#acknowledgments",
    "title": "Dupsifter Documentation",
    "section": "3 Acknowledgments",
    "text": "3 Acknowledgments\n\nThis work is based on Gregory Faust’s samblaster.\nThis work is supported by NIH/NCI R37CA230748.",
    "crumbs": [
      "Home"
    ]
  }
]